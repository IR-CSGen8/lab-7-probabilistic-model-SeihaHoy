{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c892250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the documents\n",
    "documents = [\n",
    "    \"I love cats . cats are cute pets.\",\n",
    "    \"Dogs are loyal. Dogs are good friends.\",\n",
    "    \"Birds can sing. Birds fly in the sky.\",\n",
    "    \"Fish live underwater. Fish come in many colors.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a685610",
   "metadata": {},
   "source": [
    "In this section, we define and create unigram models for the documents. Unigrams are single words or terms, and a unigram model represents the probability distribution of individual terms in the document. The unigram_model function counts the occurrences of each term in a document, calculates the probabilities, and returns the unigram model. We create unigram models for all documents in the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0e623",
   "metadata": {},
   "source": [
    "# Create Unigram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d589155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_model(document):\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    unigram_counts = defaultdict(int)\n",
    "    for word in words:\n",
    "        unigram_counts[word] += 1\n",
    "    unigram_model = {word: count / total_words for word, count in unigram_counts.items()}\n",
    "    return unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c571b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigram models for all documents\n",
    "unigram_models = [unigram_model(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a16bdec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'I': 0.125,\n",
       "  'love': 0.125,\n",
       "  'cats': 0.25,\n",
       "  '.': 0.125,\n",
       "  'are': 0.125,\n",
       "  'cute': 0.125,\n",
       "  'pets.': 0.125},\n",
       " {'Dogs': 0.2857142857142857,\n",
       "  'are': 0.2857142857142857,\n",
       "  'loyal.': 0.14285714285714285,\n",
       "  'good': 0.14285714285714285,\n",
       "  'friends.': 0.14285714285714285},\n",
       " {'Birds': 0.25,\n",
       "  'can': 0.125,\n",
       "  'sing.': 0.125,\n",
       "  'fly': 0.125,\n",
       "  'in': 0.125,\n",
       "  'the': 0.125,\n",
       "  'sky.': 0.125},\n",
       " {'Fish': 0.25,\n",
       "  'live': 0.125,\n",
       "  'underwater.': 0.125,\n",
       "  'come': 0.125,\n",
       "  'in': 0.125,\n",
       "  'many': 0.125,\n",
       "  'colors.': 0.125}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27a03456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.unigram_model(document)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faa6e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a query \n",
    "query = \"I like cats and dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85f84e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_probability(query, document_model):\n",
    "    # Tokenize the query into words\n",
    "    query_words = query.split()\n",
    "    \n",
    "    # Initialize the probability for the entire query\n",
    "    query_probability = 1.0\n",
    "    \n",
    "    # Calculate the probability for each term in the query\n",
    "    for word in query_words:\n",
    "        if word in document_model:\n",
    "            query_probability *= document_model[word]\n",
    "        else:\n",
    "            query_probability = 0.0\n",
    "            break\n",
    "    \n",
    "    return query_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25934062",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_probability = calculate_query_probability(query, unigram_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e57e1768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2641c2c",
   "metadata": {},
   "source": [
    "## Your task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e31f2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the vocabulary size\n",
    "\n",
    "def vocab(documents):\n",
    "    words = documents.split()\n",
    "    vocab = []\n",
    "    for word in words:\n",
    "        if words not in vocab:\n",
    "            vocab.append(word)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "unique_words = [vocab(doc) for doc in documents]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27e16e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'love', 'cats', '.', 'cats', 'are', 'cute', 'pets.'],\n",
       " ['Dogs', 'are', 'loyal.', 'Dogs', 'are', 'good', 'friends.'],\n",
       " ['Birds', 'can', 'sing.', 'Birds', 'fly', 'in', 'the', 'sky.'],\n",
       " ['Fish', 'live', 'underwater.', 'Fish', 'come', 'in', 'many', 'colors.']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "771db8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Laplace Smoothing for this problem\n",
    "\n",
    "#https://www.exploredatabase.com/2020/10/explain-add-1-laplace-smoothing-with-example.html\n",
    "\n",
    "def unigram_laplace(document):\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    unigram_counts = defaultdict(int)\n",
    "    for word in words:\n",
    "        unigram_counts[word] += 1\n",
    "    unigram_model = {word: ((count + 1) / (total_words + len(unigram_counts))) for word, count in unigram_counts.items()}\n",
    "    return unigram_model\n",
    "\n",
    "\n",
    "unigram_laplace = [unigram_laplace(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4b611a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'I': 0.13333333333333333,\n",
       "  'love': 0.13333333333333333,\n",
       "  'cats': 0.2,\n",
       "  '.': 0.13333333333333333,\n",
       "  'are': 0.13333333333333333,\n",
       "  'cute': 0.13333333333333333,\n",
       "  'pets.': 0.13333333333333333},\n",
       " {'Dogs': 0.25,\n",
       "  'are': 0.25,\n",
       "  'loyal.': 0.16666666666666666,\n",
       "  'good': 0.16666666666666666,\n",
       "  'friends.': 0.16666666666666666},\n",
       " {'Birds': 0.2,\n",
       "  'can': 0.13333333333333333,\n",
       "  'sing.': 0.13333333333333333,\n",
       "  'fly': 0.13333333333333333,\n",
       "  'in': 0.13333333333333333,\n",
       "  'the': 0.13333333333333333,\n",
       "  'sky.': 0.13333333333333333},\n",
       " {'Fish': 0.2,\n",
       "  'live': 0.13333333333333333,\n",
       "  'underwater.': 0.13333333333333333,\n",
       "  'come': 0.13333333333333333,\n",
       "  'in': 0.13333333333333333,\n",
       "  'many': 0.13333333333333333,\n",
       "  'colors.': 0.13333333333333333}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8cdb95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "unigram_laplace[0].keys()\n",
    "unique_word_len = sum(unigram_laplace[0].values())\n",
    "# unique_word_len = (unigram_laplace[0].values())\n",
    "print(unique_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6b5154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_query_probab_laplace(query, document_model, document):\n",
    "    # Tokenize the query into words\n",
    "    query_words = query.split()\n",
    "\n",
    "    N = len(document.split())\n",
    "    # print(N)\n",
    "    \n",
    "    unique_word_len = len(document_model.keys())\n",
    "    \n",
    "    # Initialize the probability for the entire query\n",
    "    query_probability = 1.0\n",
    "    \n",
    "    # Calculate the probability for each term in the query\n",
    "    for word in query_words:\n",
    "        if word in document_model:\n",
    "            query_probability *= document_model[word]\n",
    "        else:\n",
    "            query_probability = 1/(N + unique_word_len)\n",
    "            break\n",
    "    \n",
    "    return query_probability\n",
    "\n",
    "# query1 = calculate_query_probab_laplace(query, unigram_laplace[0], documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06d5a287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document:  1 :  0.06666666666666667\n",
      "Document:  2 :  0.08333333333333333\n",
      "Document:  3 :  0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "# query1\n",
    "for i in range(len(documents)-1):\n",
    "    query1 = calculate_query_probab_laplace(query, unigram_laplace[i], documents[i])\n",
    "    print(\"Document: \", i+1, \": \", query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7636e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = documents[0].split()\n",
    "count = words.count('cats')\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7f2705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bigram model & apply smoothing method\n",
    "def bigram_laplace(document):\n",
    "    words = document.split()\n",
    "    total_words = len(words)\n",
    "    bigram_counts = defaultdict(int)\n",
    "    for i in range(len(words)-1):\n",
    "        bigram_counts[(words[i], words[i+1])] += 1\n",
    "        #print(bigram_counts)\n",
    "    for i in range(len(words)-1):\n",
    "        word =[words[i], words[i+1]]\n",
    "        # word_count = words.count(word[1])\n",
    "        bigram_model = {word: (count + 1) / (words.count(word[1]) + len(bigram_counts)) for word, count in bigram_counts.items()}\n",
    "    return bigram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "520dd058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('I', 'love'): 0.25,\n",
       "  ('love', 'cats'): 0.2222222222222222,\n",
       "  ('cats', '.'): 0.25,\n",
       "  ('.', 'cats'): 0.2222222222222222,\n",
       "  ('cats', 'are'): 0.25,\n",
       "  ('are', 'cute'): 0.25,\n",
       "  ('cute', 'pets.'): 0.25},\n",
       " {('Dogs', 'are'): 0.42857142857142855,\n",
       "  ('are', 'loyal.'): 0.3333333333333333,\n",
       "  ('loyal.', 'Dogs'): 0.2857142857142857,\n",
       "  ('are', 'good'): 0.3333333333333333,\n",
       "  ('good', 'friends.'): 0.3333333333333333},\n",
       " {('Birds', 'can'): 0.25,\n",
       "  ('can', 'sing.'): 0.25,\n",
       "  ('sing.', 'Birds'): 0.2222222222222222,\n",
       "  ('Birds', 'fly'): 0.25,\n",
       "  ('fly', 'in'): 0.25,\n",
       "  ('in', 'the'): 0.25,\n",
       "  ('the', 'sky.'): 0.25},\n",
       " {('Fish', 'live'): 0.25,\n",
       "  ('live', 'underwater.'): 0.25,\n",
       "  ('underwater.', 'Fish'): 0.2222222222222222,\n",
       "  ('Fish', 'come'): 0.25,\n",
       "  ('come', 'in'): 0.25,\n",
       "  ('in', 'many'): 0.25,\n",
       "  ('many', 'colors.'): 0.25}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [bigram_laplace(doc) for doc in documents]\n",
    "# bigrams = [bigram_laplace(documents[0])]\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a4b147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "def calc_query_probab_bigram_laplace(query, document_model,document):\n",
    "    # Tokenize the query into words\n",
    "    query_words = query.split()\n",
    "    docs = document.split()\n",
    "    word_count = len(docs)\n",
    "\n",
    "    # Initialize the probability for the entire query\n",
    "    query_probability = 1.0\n",
    "    \n",
    "    # Calculate the probability for each term in the query\n",
    "    for i in range(len(query_words)-1):\n",
    "        word = [query_words[i], query_words[i+1]]\n",
    "        if word in document_model:\n",
    "            query_probability *= document_model[word]\n",
    "        else:\n",
    "            count = docs.count(word[1])\n",
    "            query_probability *= 1/(count + len(document_model)) \n",
    "    \n",
    "    return query_probability\n",
    "\n",
    "query2 = calculate_query_probab_laplace(query, bigrams[0], documents[0])\n",
    "print(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e05702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document  1 :  0.06666666666666667\n",
      "Document  2 :  0.06666666666666667\n",
      "Document  3 :  0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(documents)-1):\n",
    "    query2 = calculate_query_probab_laplace(query, bigrams[0], documents[0])\n",
    "    print(\"Document \", i + 1, \": \", query2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
